"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5505],{3905:function(e,t,a){a.d(t,{Zo:function(){return u},kt:function(){return N}});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),m=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=m(e.components);return n.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),p=m(a),N=r,k=p["".concat(s,".").concat(N)]||p[N]||d[N]||l;return a?n.createElement(k,i(i({ref:t},u),{},{components:a})):n.createElement(k,i({ref:t},u))}));function N(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=p;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var m=2;m<l;m++)i[m]=a[m];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},81593:function(e,t,a){a.r(t),a.d(t,{assets:function(){return u},contentTitle:function(){return s},default:function(){return N},frontMatter:function(){return o},metadata:function(){return m},toc:function(){return d}});var n=a(87462),r=a(63366),l=(a(67294),a(3905)),i=["components"],o={sidebar_position:10},s="Streaming ML",m={unversionedId:"cep/reference/extensions/execution/streamingml",id:"cep/reference/extensions/execution/streamingml",title:"Streaming ML",description:"This extension provides streaming machine learning (clustering, classification and regression) on event streams.",source:"@site/docs/cep/reference/extensions/execution/streamingml.md",sourceDirName:"cep/reference/extensions/execution",slug:"/cep/reference/extensions/execution/streamingml",permalink:"/docs/cep/reference/extensions/execution/streamingml",tags:[],version:"current",sidebarPosition:10,frontMatter:{sidebar_position:10},sidebar:"tutorialSidebar",previous:{title:"Unique",permalink:"/docs/cep/reference/extensions/execution/unique"},next:{title:"Geo Spatial",permalink:"/docs/cep/reference/extensions/execution/geospatial"}},u={},d=[{value:"Features",id:"features",level:2},{value:"bayesianRegression",id:"bayesianregression",level:2},{value:"kMeansIncremental",id:"kmeansincremental",level:2},{value:"kMeansMiniBatch",id:"kmeansminibatch",level:2},{value:"perceptronClassifier",id:"perceptronclassifier",level:2},{value:"updateBayesianRegression",id:"updatebayesianregression",level:2},{value:"updatePerceptronClassifier",id:"updateperceptronclassifier",level:2}],p={toc:d};function N(e){var t=e.components,a=(0,r.Z)(e,i);return(0,l.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"streaming-ml"},"Streaming ML"),(0,l.kt)("p",null,"This extension provides streaming machine learning (clustering, classification and regression) on event streams."),(0,l.kt)("h2",{id:"features"},"Features"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"#bayesianregression"},"bayesianRegression (StreamProcessor)"))),(0,l.kt)("p",{parentName:"li"},"  This extension predicts using a Bayesian linear regression\nmodel.Bayesian linear regression allows determining the uncertainty\nof each prediction by estimating the full-predictive distribution")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"#kmeansincremental"},"kMeansIncremental (StreamProcessor)"))),(0,l.kt)("p",{parentName:"li"},"  Performs K-Means clustering on a streaming data set. Data points can\nbe of any dimension and the dimensionality is calculated from number\nof parameters. All data points to be processed by a query should be\nof the same dimensionality. The Euclidean distance is taken as the\ndistance metric. The algorithm resembles Sequential K-Means\nClustering at\n",(0,l.kt)("a",{parentName:"p",href:"https://www.cs.princeton.edu/courses/archive/fall08/cos436/Duda/C/sk_means.htm"},"https://www.cs.princeton.edu/courses/archive/fall08/cos436/Duda/C/sk_means.htm"))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"#kmeansminibatch"},"kMeansMiniBatch (StreamProcessor)"))),(0,l.kt)("p",{parentName:"li"},"  Performs K-Means clustering on a streaming data set. Data points can\nbe of any dimension and the dimensionality is calculated from number\nof parameters. All data points to be processed in a single query\nshould be of the same dimensionality. The Euclidean distance is\ntaken as the distance metric. The algorithm resembles mini-batch\nK-Means. (refer Web-Scale K-Means Clustering by D.Sculley, Google,\nInc.).")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"#perceptronclassifier"},"perceptronClassifier (StreamProcessor)"))),(0,l.kt)("p",{parentName:"li"},"  This extension predicts using a linear binary classification\nPerceptron model.")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"#updatebayesianregression"},"updateBayesianRegression (StreamProcessor)"))),(0,l.kt)("p",{parentName:"li"},"  This extension builds/updates a linear Bayesian regression model.\nThis extension uses an improved version of stochastic variational\ninference.")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("a",{parentName:"strong",href:"#updateperceptronclassifier"},"updatePerceptronClassifier (StreamProcessor)"))),(0,l.kt)("p",{parentName:"li"},"  This extension builds/updates a linear binary classification\nPerceptron model."))),(0,l.kt)("h2",{id:"bayesianregression"},"bayesianRegression"),(0,l.kt)("p",null,"This extension predicts using a Bayesian linear regression\nmodel.Bayesian linear regression allows determining the uncertainty of\neach prediction by estimating the full-predictive distribution"),(0,l.kt)("p",null,"Syntax"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"streamingml:bayesianRegression(<STRING> model.name, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:bayesianRegression(<STRING> model.name, <INT> prediction.samples, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\n")),(0,l.kt)("p",null,"QUERY PARAMETERS"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default Value"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Data Types"),(0,l.kt)("th",{parentName:"tr",align:null},"Optional"),(0,l.kt)("th",{parentName:"tr",align:null},"Dynamic"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.name"),(0,l.kt)("td",{parentName:"tr",align:null},"The name of the model to be used"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"STRING"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"prediction.samples"),(0,l.kt)("td",{parentName:"tr",align:null},"The number of samples to be drawn to estimate the prediction"),(0,l.kt)("td",{parentName:"tr",align:null},"1000"),(0,l.kt)("td",{parentName:"tr",align:null},"INT"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.feature"),(0,l.kt)("td",{parentName:"tr",align:null},"The features of the model that need to be attributes of the stream"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE FLOAT INT LONG"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,l.kt)("p",null,"Extra Return Attributes"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Types"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"prediction"),(0,l.kt)("td",{parentName:"tr",align:null},"The predicted value (double)"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"confidence"),(0,l.kt)("td",{parentName:"tr",align:null},"Inverse of the standard deviation of the predictive distribution"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")))),(0,l.kt)("p",null,"EXAMPLE 1"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double, attribute_3 double);\n\nfrom StreamA#streamingml:bayesianRegression('model1', attribute_0, attribute_1, attribute_2, attribute_3)\ninsert all events into OutputStream;\n")),(0,l.kt)("p",null,"This query uses a Bayesian regression model named ",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," to predict\nthe label of the feature vector represented by ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),",\n",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),", and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_3"),". The predicted value is\nemitted to the ",(0,l.kt)("inlineCode",{parentName:"p"},"OutputStream")," streamalong with the prediction confidence\n(std of predictive distribution) and the feature vector. As a result,\nthe OutputStream stream is defined as follows: (attribute_0 double,\nattribute_1 double, attribute_2 double, attribute_3 double,\nprediction double, confidence double)."),(0,l.kt)("h2",{id:"kmeansincremental"},"kMeansIncremental"),(0,l.kt)("p",null,"Performs K-Means clustering on a streaming data set. Data points can be\nof any dimension and the dimensionality is calculated from number of\nparameters. All data points to be processed by a query should be of the\nsame dimensionality. The Euclidean distance is taken as the distance\nmetric. The algorithm resembles Sequential K-Means Clustering at\n",(0,l.kt)("a",{parentName:"p",href:"https://www.cs.princeton.edu/courses/archive/fall08/cos436/Duda/C/sk_means.htm"},"https://www.cs.princeton.edu/courses/archive/fall08/cos436/Duda/C/sk_means.htm")),(0,l.kt)("p",null,"Syntax"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"streamingml:kMeansIncremental(<INT> no.of.clusters, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansIncremental(<INT> no.of.clusters, <DOUBLE> decay.rate, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\n")),(0,l.kt)("p",null,"QUERY PARAMETERS"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default Value"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Data Types"),(0,l.kt)("th",{parentName:"tr",align:null},"Optional"),(0,l.kt)("th",{parentName:"tr",align:null},"Dynamic"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"no.of.clusters"),(0,l.kt)("td",{parentName:"tr",align:null},"The assumed number of natural clusters in the data set."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"INT"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"decay.rate"),(0,l.kt)("td",{parentName:"tr",align:null},"this is the decay rate of old data compared to new data. Value of this will be in ","[0,1]",". 0 means only old data used and1 will mean that only new data is used"),(0,l.kt)("td",{parentName:"tr",align:null},"0.01"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.feature"),(0,l.kt)("td",{parentName:"tr",align:null},"This is a variable length argument. Depending on the dimensionality of data points we will receive coordinates as features along each axis."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE FLOAT INT LONG"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,l.kt)("p",null,"Extra Return Attributes"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Types"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"euclideanDistanceToClosestCentroid"),(0,l.kt)("td",{parentName:"tr",align:null},"Represents the Euclidean distance between the current data point and the closest centroid."),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"closestCentroidCoordinate"),(0,l.kt)("td",{parentName:"tr",align:null},"This is a variable length attribute. Depending on the dimensionality(D) we will return closestCentroidCoordinate1, closestCentroidCoordinate2,... closestCentroidCoordinateD which are the d dimensional coordinates of the closest centroid from the model to the current event. This is the prediction result and this represents the cluster to which the current event belongs to."),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")))),(0,l.kt)("p",null,"EXAMPLE 1"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream InputStream (x double, y double);\n@info(name = 'query1')\nselect closestCentroidCoordinate1, closestCentroidCoordinate2, x, y    \nfrom InputStream#streamingml:kMeansIncremental(2, 0.2, x, y)\ninsert into OutputStream;\n")),(0,l.kt)("p",null,"This is an example where user provides the decay rate. First two events\nwill be used to initiate the model since the required number of clusters\nis specified as 2. After the first event itself prediction would start."),(0,l.kt)("p",null,"EXAMPLE 2"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream InputStream (x double, y double);\n@info(name = 'query1')\nselect closestCentroidCoordinate1, closestCentroidCoordinate2, x, y    \nfrom InputStream#streamingml:kMeansIncremental(2, x, y)\ninsert into OutputStream;\n")),(0,l.kt)("p",null,"This is an example where user doesnt give the decay rate so the default\nvalue will be used"),(0,l.kt)("h2",{id:"kmeansminibatch"},"kMeansMiniBatch"),(0,l.kt)("p",null,"Performs K-Means clustering on a streaming data set. Data points can be\nof any dimension and the dimensionality is calculated from number of\nparameters. All data points to be processed in a single query should be\nof the same dimensionality. The Euclidean distance is taken as the\ndistance metric. The algorithm resembles mini-batch K-Means. (refer\nWeb-Scale K-Means Clustering by D.Sculley, Google, Inc.)."),(0,l.kt)("p",null,"Syntax"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"streamingml:kMeansMiniBatch(<INT> no.of.clusters, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansMiniBatch(<INT> no.of.clusters, <DOUBLE> decay.rate, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansMiniBatch(<INT> no.of.clusters, <INT> maximum.iterations, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansMiniBatch(<INT> no.of.clusters, <INT> no.of.events.to.retrain, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansMiniBatch(<INT> no.of.clusters, <DOUBLE> decay.rate, <INT> maximum.iterations, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansMiniBatch(<INT> no.of.clusters, <DOUBLE> decay.rate, <INT> no.of.events.to.retrain, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansMiniBatch(<INT> no.of.clusters, <INT> maximum.iterations, <INT> no.of.events.to.retrain, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:kMeansMiniBatch(<INT> no.of.clusters, <DOUBLE> decay.rate, <INT> maximum.iterations, <INT> no.of.events.to.retrain, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\n")),(0,l.kt)("p",null,"QUERY PARAMETERS"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default Value"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Data Types"),(0,l.kt)("th",{parentName:"tr",align:null},"Optional"),(0,l.kt)("th",{parentName:"tr",align:null},"Dynamic"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"no.of.clusters"),(0,l.kt)("td",{parentName:"tr",align:null},"The assumed number of natural clusters in the data set."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"INT"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"decay.rate"),(0,l.kt)("td",{parentName:"tr",align:null},"this is the decay rate of old data compared to new data. Value of this will be in ","[0,1]",". 0 means only old data used and1 will mean that only new data is used"),(0,l.kt)("td",{parentName:"tr",align:null},"0.01"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"maximum.iterations"),(0,l.kt)("td",{parentName:"tr",align:null},"Number of iterations, the process iterates until the number of maximum iterations is reached or the centroids do not change"),(0,l.kt)("td",{parentName:"tr",align:null},"50"),(0,l.kt)("td",{parentName:"tr",align:null},"INT"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"no.of.events.to.retrain"),(0,l.kt)("td",{parentName:"tr",align:null},"number of events to recalculate cluster centers."),(0,l.kt)("td",{parentName:"tr",align:null},"20"),(0,l.kt)("td",{parentName:"tr",align:null},"INT"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.feature"),(0,l.kt)("td",{parentName:"tr",align:null},"This is a variable length argument. Depending on the dimensionality of data points we will receive coordinates as features along each axis."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE FLOAT INT LONG"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,l.kt)("p",null,"Extra Return Attributes"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Types"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"euclideanDistanceToClosestCentroid"),(0,l.kt)("td",{parentName:"tr",align:null},"Represents the Euclidean distance between the current data point and the closest centroid."),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"closestCentroidCoordinate"),(0,l.kt)("td",{parentName:"tr",align:null},"This is a variable length attribute. Depending on the dimensionality(d) we will return closestCentroidCoordinate1 to closestCentroidCoordinated which are the d dimensional coordinates of the closest centroid from the model to the current event. This is the prediction result and this represents the cluster towhich the current event belongs to."),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")))),(0,l.kt)("p",null,"EXAMPLE 1"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream InputStream (x double, y double);\n@info(name = 'query1')\nselect closestCentroidCoordinate1, closestCentroidCoordinate2, x, y    \nfrom InputStream#streamingml:kMeansMiniBatch(2, 0.2, 10, 20, x, y)\ninsert into OutputStream;\n")),(0,l.kt)("p",null,"This is an example where user gives all three hyper parameters. first 20\nevents will be consumed to build the model and from the 21st event\nprediction would start"),(0,l.kt)("p",null,"EXAMPLE 2"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream InputStream (x double, y double);\n@info(name = 'query1')\nselect closestCentroidCoordinate1, closestCentroidCoordinate2, x, y    \nfrom InputStream#streamingml:kMeansMiniBatch(2, x, y)\ninsert into OutputStream;\n")),(0,l.kt)("p",null,"This is an example where user has not specified hyper params. So default\nvalues will be used."),(0,l.kt)("h2",{id:"perceptronclassifier"},"perceptronClassifier"),(0,l.kt)("p",null,"This extension predicts using a linear binary classification Perceptron\nmodel."),(0,l.kt)("p",null,"Syntax"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"streamingml:perceptronClassifier(<STRING> model.name, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:perceptronClassifier(<STRING> model.name, <DOUBLE> model.bias, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:perceptronClassifier(<STRING> model.name, <DOUBLE> model.threshold, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:perceptronClassifier(<STRING> model.name, <DOUBLE> model.bias, <DOUBLE> model.threshold, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\n")),(0,l.kt)("p",null,"QUERY PARAMETERS"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default Value"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Data Types"),(0,l.kt)("th",{parentName:"tr",align:null},"Optional"),(0,l.kt)("th",{parentName:"tr",align:null},"Dynamic"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.name"),(0,l.kt)("td",{parentName:"tr",align:null},"The name of the model to be used."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"STRING"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.bias"),(0,l.kt)("td",{parentName:"tr",align:null},"The bias of the Perceptron algorithm."),(0,l.kt)("td",{parentName:"tr",align:null},"0.0"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.threshold"),(0,l.kt)("td",{parentName:"tr",align:null},"The threshold that separates the two classes. The value specified must be between zero and one."),(0,l.kt)("td",{parentName:"tr",align:null},"0.5"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.feature"),(0,l.kt)("td",{parentName:"tr",align:null},"The features of the model that need to be attributes of the stream."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE FLOAT INT LONG"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,l.kt)("p",null,"Extra Return Attributes"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Types"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"prediction"),(0,l.kt)("td",{parentName:"tr",align:null},"The predicted value (",(0,l.kt)("inlineCode",{parentName:"td"},"true/false"),")"),(0,l.kt)("td",{parentName:"tr",align:null},"BOOL")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"confidenceLevel"),(0,l.kt)("td",{parentName:"tr",align:null},"The probability of the prediction"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")))),(0,l.kt)("p",null,"EXAMPLE 1"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double, attribute_3 double);\n\nfrom StreamA#streamingml:perceptronClassifier('model1',0.0,0.5, attribute_0, attribute_1, attribute_2, attribute_3)\ninsert all events into OutputStream;\n")),(0,l.kt)("p",null,"This query uses a Perceptron model named ",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," with a ",(0,l.kt)("inlineCode",{parentName:"p"},"0.0")," bias and\na ",(0,l.kt)("inlineCode",{parentName:"p"},"0.5")," threshold learning rate to predict the label of the feature\nvector represented by ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),", and\n",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_3"),". The predicted label (",(0,l.kt)("inlineCode",{parentName:"p"},"true/false"),") is emitted to the\n",(0,l.kt)("inlineCode",{parentName:"p"},"OutputStream")," streamalong with the prediction confidence\nlevel(probability) and the feature vector. As a result, the OutputStream\nstream is defined as follows: (attribute_0 double, attribute_1 double,\nattribute_2 double, attribute_3 double, prediction bool,\nconfidenceLevel double)."),(0,l.kt)("p",null,"EXAMPLE 2"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double, attribute_3 double);\n\nfrom StreamA#streamingml:perceptronClassifier('model1',0.0, attribute_0, attribute_1, attribute_2, attribute_3)\ninsert all events into OutputStream;\n")),(0,l.kt)("p",null,"This query uses a Perceptron model named ",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," with a ",(0,l.kt)("inlineCode",{parentName:"p"},"0.0")," bias to\npredict the label of the feature vector represented by ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),",\n",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),", and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_3"),". The\nprediction(",(0,l.kt)("inlineCode",{parentName:"p"},"true/false"),") is emitted to the ",(0,l.kt)("inlineCode",{parentName:"p"},"OutputStream"),"stream along\nwith the prediction confidence level(probability) and the feature. As a\nresult, the OutputStream stream is defined as follows: (attribute_0\ndouble, attribute_1 double, attribute_2 double, attribute_3 double,\nprediction bool, confidenceLevel double)."),(0,l.kt)("p",null,"EXAMPLE 3"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double, attribute_3 double);\n\nfrom StreamA#streamingml:perceptronClassifier(`model1`, attribute_0, attribute_1, attribute_2)\ninsert all events into OutputStream;\n")),(0,l.kt)("p",null,"This query uses a Perceptron model named ",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," with a default 0.0\nbias to predict the label of the feature vector represented by\n",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),", and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),". The predicted\nprobability is emitted to the OutputStream stream along with the feature\nvector. As a result, the OutputStream is defined as follows:\n(attribute_0 double, attribute_1 double, attribute_2 double,\nattribute_3 double, prediction bool, confidenceLevel double)."),(0,l.kt)("h2",{id:"updatebayesianregression"},"updateBayesianRegression"),(0,l.kt)("p",null,"This extension builds/updates a linear Bayesian regression model. This\nextension uses an improved version of stochastic variational inference."),(0,l.kt)("p",null,"Syntax"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"streamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <INT> model.samples, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <STRING> model.optimizer, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <DOUBLE> learning.rate, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <INT> model.samples, <STRING> model.optimizer, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <INT> model.samples, <DOUBLE> learning.rate, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <STRING> model.optimizer, <DOUBLE> learning.rate, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updateBayesianRegression(<STRING> model.name, <INT|DOUBLE|LONG|FLOAT> model.target, <INT> model.samples, <STRING> model.optimizer, <DOUBLE> learning.rate, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\n")),(0,l.kt)("p",null,"QUERY PARAMETERS"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default Value"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Data Types"),(0,l.kt)("th",{parentName:"tr",align:null},"Optional"),(0,l.kt)("th",{parentName:"tr",align:null},"Dynamic"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.name"),(0,l.kt)("td",{parentName:"tr",align:null},"The name of the model to be built."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"STRING"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.target"),(0,l.kt)("td",{parentName:"tr",align:null},"The target attribute (dependant variable) of the input stream."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"INT DOUBLE LONG FLOAT"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.samples"),(0,l.kt)("td",{parentName:"tr",align:null},"Number of samples used to construct the gradients."),(0,l.kt)("td",{parentName:"tr",align:null},"1"),(0,l.kt)("td",{parentName:"tr",align:null},"INT"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.optimizer"),(0,l.kt)("td",{parentName:"tr",align:null},"The type of optimization used"),(0,l.kt)("td",{parentName:"tr",align:null},"ADAM"),(0,l.kt)("td",{parentName:"tr",align:null},"STRING"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"learning.rate"),(0,l.kt)("td",{parentName:"tr",align:null},"The learning rate of the updater"),(0,l.kt)("td",{parentName:"tr",align:null},"0.05"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.feature"),(0,l.kt)("td",{parentName:"tr",align:null},"Features of the model that need to be attributes of the stream."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE FLOAT INT LONG"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,l.kt)("p",null,"Extra Return Attributes"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Types"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"loss"),(0,l.kt)("td",{parentName:"tr",align:null},"loss of the model."),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")))),(0,l.kt)("p",null,"EXAMPLE 1"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double, attribute_3 double, attribute_4 double );\n\nfrom StreamA#streamingml:updateBayesianRegression('model1', attribute_4, attribute_0, attribute_1, attribute_2, attribute_3)\ninsert all events into outputStream;\n")),(0,l.kt)("p",null,"This query builds/updates a Bayesian Linear regression model named\n",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," using ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),", and\n",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_3")," as features, and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_4")," as the label. Updated\nweights of the model are emitted to the OutputStream stream."),(0,l.kt)("p",null,"EXAMPLE 2"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double, attribute_3 double, attribute_4 double );\n\nfrom StreamA#streamingml:updateBayesianRegression('model1', attribute_4, 2, 'NADAM', 0.01, attribute_0, attribute_1, attribute_2, attribute_3)\ninsert all events into outputStream;\n")),(0,l.kt)("p",null,"This query builds/updates a Bayesian Linear regression model named\n",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," with a ",(0,l.kt)("inlineCode",{parentName:"p"},"0.01")," learning rate using ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),",\n",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),", and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_3")," as features, and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_4")," as the\nlabel. Updated weights of the model are emitted to the OutputStream\nstream. This model draws two samples during monte-carlo integration and\nuses NADAM optimizer."),(0,l.kt)("h2",{id:"updateperceptronclassifier"},"updatePerceptronClassifier"),(0,l.kt)("p",null,"This extension builds/updates a linear binary classification Perceptron\nmodel."),(0,l.kt)("p",null,"Syntax"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"streamingml:updatePerceptronClassifier(<STRING> model.name, <BOOL|STRING> model.label, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\nstreamingml:updatePerceptronClassifier(<STRING> model.name, <BOOL|STRING> model.label, <DOUBLE> learning.rate, <DOUBLE|FLOAT|INT|LONG> model.feature, <DOUBLE|FLOAT|INT|LONG> ...)\n")),(0,l.kt)("p",null,"QUERY PARAMETERS"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default Value"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Data Types"),(0,l.kt)("th",{parentName:"tr",align:null},"Optional"),(0,l.kt)("th",{parentName:"tr",align:null},"Dynamic"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.name"),(0,l.kt)("td",{parentName:"tr",align:null},"The name of the model to be built/updated."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"STRING"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.label"),(0,l.kt)("td",{parentName:"tr",align:null},"The attribute of the label or the class of the dataset."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"BOOL STRING"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"learning.rate"),(0,l.kt)("td",{parentName:"tr",align:null},"The learning rate of the Perceptron algorithm."),(0,l.kt)("td",{parentName:"tr",align:null},"0.1"),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes"),(0,l.kt)("td",{parentName:"tr",align:null},"No")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"model.feature"),(0,l.kt)("td",{parentName:"tr",align:null},"Features of the model that need to be attributes of the stream."),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE FLOAT INT LONG"),(0,l.kt)("td",{parentName:"tr",align:null},"No"),(0,l.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,l.kt)("p",null,"Extra Return Attributes"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Possible Types"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"featureWeight"),(0,l.kt)("td",{parentName:"tr",align:null},"Weight of the ",(0,l.kt)("inlineCode",{parentName:"td"},"feature.name")," of the model."),(0,l.kt)("td",{parentName:"tr",align:null},"DOUBLE")))),(0,l.kt)("p",null,"EXAMPLE 1"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double, attribute_3 double, attribute_4 string );\n\nfrom StreamA#streamingml:updatePerceptronClassifier('model1', attribute_4, 0.01, attribute_0, attribute_1, attribute_2, attribute_3)\ninsert all events into outputStream;\n")),(0,l.kt)("p",null,"This query builds/updates a Perceptron model named ",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," with a\n",(0,l.kt)("inlineCode",{parentName:"p"},"0.01")," learning rate using ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),",\nand ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_3")," as features, and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_4")," as the label. Updated\nweights of the model are emitted to the OutputStream stream."),(0,l.kt)("p",null,"EXAMPLE 2"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"define stream StreamA (attribute_0 double, attribute_1 double, attribute_2 double,attribute_3 double, attribute_4 string );\n\n from StreamA#streamingml:updatePerceptronClassifier('model1', attribute_4, attribute_0, attribute_1, attribute_2, attribute_3)\ninsert all events into outputStream;\n")),(0,l.kt)("p",null,"This query builds/updates a Perceptron model named ",(0,l.kt)("inlineCode",{parentName:"p"},"model1")," with a\ndefault ",(0,l.kt)("inlineCode",{parentName:"p"},"0.1")," learning rate using ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_0"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_1"),",\n",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_2"),", and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_3")," as features, and ",(0,l.kt)("inlineCode",{parentName:"p"},"attribute_4")," as the\nlabel. The updated weights of the model are appended to the\noutputStream."))}N.isMDXComponent=!0}}]);