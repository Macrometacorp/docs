"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4213],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>u});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),s=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,p=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),c=s(a),u=r,k=c["".concat(p,".").concat(u)]||c[u]||d[u]||i;return a?n.createElement(k,o(o({ref:t},m),{},{components:a})):n.createElement(k,o({ref:t},m))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=c;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var s=2;s<i;s++)o[s]=a[s];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},38385:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var n=a(87462),r=(a(67294),a(3905));const i={title:"kafka (Source)"},o=void 0,l={unversionedId:"cep/source/kafka",id:"cep/source/kafka",title:"kafka (Source)",description:"A Kafka source receives events to be processed by gdn SP from a topic",source:"@site/docs/cep/source/kafka.md",sourceDirName:"cep/source",slug:"/cep/source/kafka",permalink:"/docs/cep/source/kafka",draft:!1,editUrl:"https://github.com/macrometacorp/docs/edit/main/docs/cep/source/kafka.md",tags:[],version:"current",frontMatter:{title:"kafka (Source)"},sidebar:"defaultSidebar",previous:{title:"inMemory (Source)",permalink:"/docs/cep/source/inMemory"},next:{title:"kafkaMultiDC (Source)",permalink:"/docs/cep/source/kafkaMultiDC"}},p={},s=[{value:"Syntax",id:"syntax",level:2},{value:"Query Parameters",id:"query-parameters",level:2},{value:"Example 1",id:"example-1",level:2},{value:"Example 2",id:"example-2",level:2}],m={toc:s};function d(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"A Kafka source receives events to be processed by gdn SP from a topic\nwith a partition for a Kafka cluster. The events received can be in the\n",(0,r.kt)("inlineCode",{parentName:"p"},"TEXT")," ",(0,r.kt)("inlineCode",{parentName:"p"},"XML")," ",(0,r.kt)("inlineCode",{parentName:"p"},"JSON")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"Binary")," format. If the topic is not already\ncreated in the Kafka cluster, the Kafka sink creates the default\npartition for the given topic."),(0,r.kt)("h2",{id:"syntax"},"Syntax"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'CREATE SOURCE <NAME> WITH (type="kafka", map.type="<STRING>", bootstrap.servers="<STRING>", topic.list="<STRING>", group.id="<STRING>", threading.option="<STRING>", partition.no.list="<STRING>", seq.enabled="<BOOL>", is.binary.message="<BOOL>", topic.offsets.map="<STRING>", enable.offsets.commit="<BOOL>", optional.configuration="<STRING>")\n')),(0,r.kt)("h2",{id:"query-parameters"},"Query Parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Name"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Default Value"),(0,r.kt)("th",{parentName:"tr",align:null},"Possible Data Types"),(0,r.kt)("th",{parentName:"tr",align:null},"Optional"),(0,r.kt)("th",{parentName:"tr",align:null},"Dynamic"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"bootstrap.servers"),(0,r.kt)("td",{parentName:"tr",align:null},"This specifies the list of Kafka servers to which the Kafka source must listen. This list can be provided as a set of comma-separated values. e.g., ",(0,r.kt)("inlineCode",{parentName:"td"},"localhost:9092,localhost:9093")),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},"STRING"),(0,r.kt)("td",{parentName:"tr",align:null},"No"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"topic.list"),(0,r.kt)("td",{parentName:"tr",align:null},"This specifies the list of topics to which the source must listen. This list can be provided as a set of comma-separated values. e.g., ",(0,r.kt)("inlineCode",{parentName:"td"},"topic_one,topic_two")),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},"STRING"),(0,r.kt)("td",{parentName:"tr",align:null},"No"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"group.id"),(0,r.kt)("td",{parentName:"tr",align:null},"This is an ID to identify the Kafka source group. The group ID ensures that sources with the same topic and partition that are in the same group do not receive the same event."),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},"STRING"),(0,r.kt)("td",{parentName:"tr",align:null},"No"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"threading.option"),(0,r.kt)("td",{parentName:"tr",align:null},"This specifies whether the Kafka source is to be run on a single thread, or in multiple threads based on a condition. Possible values are as follows: ",(0,r.kt)("inlineCode",{parentName:"td"},"single.thread"),": To run the Kafka source on a single thread. ",(0,r.kt)("inlineCode",{parentName:"td"},"topic.wise"),": To use a separate thread per topic. ",(0,r.kt)("inlineCode",{parentName:"td"},"partition.wise"),": To use a separate thread per partition."),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},"STRING"),(0,r.kt)("td",{parentName:"tr",align:null},"No"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"partition.no.list"),(0,r.kt)("td",{parentName:"tr",align:null},"The partition number list for the given topic. This is provided as a list of comma-separated values. e.g., ",(0,r.kt)("inlineCode",{parentName:"td"},"0,1,2,"),"."),(0,r.kt)("td",{parentName:"tr",align:null},"0"),(0,r.kt)("td",{parentName:"tr",align:null},"STRING"),(0,r.kt)("td",{parentName:"tr",align:null},"Yes"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"seq.enabled"),(0,r.kt)("td",{parentName:"tr",align:null},"If this parameter is set to ",(0,r.kt)("inlineCode",{parentName:"td"},"true"),", the sequence of the events received via the source is taken into account. Therefore, each event should contain a sequence number as an attribute value to indicate the sequence."),(0,r.kt)("td",{parentName:"tr",align:null},"false"),(0,r.kt)("td",{parentName:"tr",align:null},"BOOL"),(0,r.kt)("td",{parentName:"tr",align:null},"Yes"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"is.binary.message"),(0,r.kt)("td",{parentName:"tr",align:null},"In order to receive binary events via the Kafka source,it is required to setthis parameter to ",(0,r.kt)("inlineCode",{parentName:"td"},"True"),"."),(0,r.kt)("td",{parentName:"tr",align:null},"false"),(0,r.kt)("td",{parentName:"tr",align:null},"BOOL"),(0,r.kt)("td",{parentName:"tr",align:null},"Yes"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"topic.offsets.map"),(0,r.kt)("td",{parentName:"tr",align:null},"This parameter specifies reading offsets for each topic and partition. The value for this parameter is specified in the following format:  ",(0,r.kt)("inlineCode",{parentName:"td"},"<topic>=<offset>,<topic>=<offset>,"),"   When an offset is defined for a topic, the Kafka source skips reading the message with the number specified as the offset as well as all the messages sent previous to that message. If the offset is not defined for a specific topic it reads messages from the beginning. e.g., ",(0,r.kt)("inlineCode",{parentName:"td"},"stocks=100,trades=50")," reads from the 101th message of the ",(0,r.kt)("inlineCode",{parentName:"td"},"stocks")," topic, and from the 51st message of the ",(0,r.kt)("inlineCode",{parentName:"td"},"trades")," topic."),(0,r.kt)("td",{parentName:"tr",align:null},"null"),(0,r.kt)("td",{parentName:"tr",align:null},"STRING"),(0,r.kt)("td",{parentName:"tr",align:null},"Yes"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"enable.offsets.commit"),(0,r.kt)("td",{parentName:"tr",align:null},"This parameter specifies whether to commit offsets. If the manual asynchronous offset committing is needed, ",(0,r.kt)("inlineCode",{parentName:"td"},"enable.offsets.commit")," should be ",(0,r.kt)("inlineCode",{parentName:"td"},"true")," and ",(0,r.kt)("inlineCode",{parentName:"td"},"enable.auto.commit")," should be ",(0,r.kt)("inlineCode",{parentName:"td"},"false"),". If periodical committing is needed ",(0,r.kt)("inlineCode",{parentName:"td"},"enable.offsets.commit")," should be ",(0,r.kt)("inlineCode",{parentName:"td"},"true")," and ",(0,r.kt)("inlineCode",{parentName:"td"},"enable.auto.commit")," should be ",(0,r.kt)("inlineCode",{parentName:"td"},"true"),". If committing is not needed, ",(0,r.kt)("inlineCode",{parentName:"td"},"enable.offsets.commit")," should be ",(0,r.kt)("inlineCode",{parentName:"td"},"false"),". Note: ",(0,r.kt)("inlineCode",{parentName:"td"},"enable.auto.commit")," is an ",(0,r.kt)("inlineCode",{parentName:"td"},"optional.configuration")," property. If it is set to ",(0,r.kt)("inlineCode",{parentName:"td"},"true"),", Source will periodically(default: 1000ms. Configurable with ",(0,r.kt)("inlineCode",{parentName:"td"},"auto.commit.interval.ms")," property as an ",(0,r.kt)("inlineCode",{parentName:"td"},"optional.configuration"),") commit its current offset (defined as the offset of the next message to be read) for the partitions it is reading from back to Kafka. To guarantee at-least-once processing, we recommend you to enable Stream App Periodic State Persistence when ",(0,r.kt)("inlineCode",{parentName:"td"},"enable.auto.commit")," property is set to ",(0,r.kt)("inlineCode",{parentName:"td"},"true"),". During manual committing, it might introduce a latency during consumption."),(0,r.kt)("td",{parentName:"tr",align:null},"true"),(0,r.kt)("td",{parentName:"tr",align:null},"BOOL"),(0,r.kt)("td",{parentName:"tr",align:null},"Yes"),(0,r.kt)("td",{parentName:"tr",align:null},"No")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"optional.configuration"),(0,r.kt)("td",{parentName:"tr",align:null},"This parameter contains all the other possible configurations that the consumer is created with. e.g., ",(0,r.kt)("inlineCode",{parentName:"td"},"ssl.keystore.type:JKS,batch.size:200"),"."),(0,r.kt)("td",{parentName:"tr",align:null},"null"),(0,r.kt)("td",{parentName:"tr",align:null},"STRING"),(0,r.kt)("td",{parentName:"tr",align:null},"Yes"),(0,r.kt)("td",{parentName:"tr",align:null},"No")))),(0,r.kt)("h2",{id:"example-1"},"Example 1"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"@App:name('TestExecutionPlan')\nCREATE STREAM BarStream (symbol string, price float, volume long);\n\nCREATE SOURCE FooStream WITH (type='kafka', topic.list='kafka_topic,kafka_topic2', group.id='test', threading.option='partition.wise', bootstrap.servers='localhost:9092', partition.no.list='0,1', map.type='json') (symbol string, price float, volume long);\n\n@info(name = 'query1')\ninsert into BarStream\nfrom FooStream select symbol, price, volume ;\n")),(0,r.kt)("p",null,"This kafka source configuration listens to the ",(0,r.kt)("inlineCode",{parentName:"p"},"kafka_topic")," and\n",(0,r.kt)("inlineCode",{parentName:"p"},"kafka_topic2")," topics with ",(0,r.kt)("inlineCode",{parentName:"p"},"0")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"1")," partitions. A thread is created\nfor each topic and partition combination. The events are received in the\nJSON format, mapped to a Stream App event, and sent to a stream named\n",(0,r.kt)("inlineCode",{parentName:"p"},"FooStream"),"."),(0,r.kt)("h2",{id:"example-2"},"Example 2"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"@App:name('TestExecutionPlan')\nCREATE STREAM BarStream (symbol string, price float, volume long);\n\nCREATE SOURCE FooStream WITH (type='kafka', topic.list='kafka_topic', group.id='test', threading.option='single.thread', bootstrap.servers='localhost:9092', map.type='json') (symbol string, price float, volume long);\n\n@info(name = 'query1')\ninsert into BarStream\nfrom FooStream select symbol, price, volume ;\n")),(0,r.kt)("p",null,"This Kafka source configuration listens to the ",(0,r.kt)("inlineCode",{parentName:"p"},"kafka_topic")," topic for\nthe default partition because no ",(0,r.kt)("inlineCode",{parentName:"p"},"partition.no.list")," is defined. Only\none thread is created for the topic. The events are received in the JSON\nformat, mapped to a Stream App event, and sent to a stream named\n",(0,r.kt)("inlineCode",{parentName:"p"},"FooStream"),"."))}d.isMDXComponent=!0}}]);